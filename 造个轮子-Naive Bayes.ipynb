{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义NB模型\n",
    "#### 输入\n",
    "- X_train,Y_train,X_test,Y_test\n",
    "    - 其中，X为文本特征向量化处理后(CountVectorizer)的array数组，Y为X对应的分类标签list，X的行业与Y一一对应\n",
    "    \n",
    "#### 输出\n",
    "- X_test各样本的预测分类结果Y_predict，以及分类准确率\n",
    "\n",
    "#### 过程\n",
    "- 利用训练集各特征词出现的频率和对应标签概率，训练NB模型各概率参数\n",
    "- 求测试集各特征在训练集对应的先验概率\n",
    "- 将测试集各特征在训练集对应的先验概率乘以条件概率P(Y=ck)，得到测试集各样本后验概率，取后验概率最大的标签类别为该测试样本类别\n",
    "\n",
    "#### 1. 利用训练集，训练概率参数（拉普拉斯平滑）[类似mnb.fit()]\n",
    "- 条件概率：P(Y=ck)\n",
    "- 先验概率：P(X1=0|Y=ck),P(X1=1|Y=ck),P(X2=0|Y=ck)……\n",
    "\n",
    "#### 2. 将测试集各特征向量值带入训练的概率参数中，计算后验概率，取使后验概率最大的Y=ck为测试样本的分类[类似mnb.predict(), mnb.predict_proba()]\n",
    "- 测试集样本特征向量为0时，不将刚才训练的对应概率参数纳入计算\n",
    "- 测试集样本特征向量>=1时(即测试样本出现该特征向量的词)，将刚才训练的特征向量对应的概率参数纳入计算\n",
    "- 分别计算垃圾邮件下和正常邮件下每个样本的后验概率，取后验概率最大的类别为样本分类\n",
    "\n",
    "#### 3. 计算分类准确率 [类似mnb.score()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "输入：X_train,Y_train,X_test,Y_test\n",
    "    其中，X为文本特征向量化处理后(CountVectorizer)的array，Y为X对应的分类标签list，XY一一对应\n",
    "输出：X_test各样本的预测分类结果Y_predict，分类准确率\n",
    "    其中，0-正常邮件，1-垃圾邮件\n",
    "\"\"\"\n",
    "def wheel_nb(X_train,Y_train,X_test,Y_test):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    \n",
    "    #先将训练集的内容和标签合为一个dataframe\n",
    "    d={\"content\":X_train.tolist(),\"label\":Y_train}\n",
    "    emails_train=pd.DataFrame(data=d)\n",
    "\n",
    "    #将正常邮件(Y=0)和垃圾邮件(Y=1)分为两个子集\n",
    "    normal=emails_train[emails_train.label==0]\n",
    "    normal.reset_index(inplace=True,drop=True) #重置normal索引，作用于原表，丢弃之前的索引\n",
    "    spam=emails_train[emails_train.label==1]\n",
    "    spam.reset_index(inplace=True,drop=True) #重置spam索引，作用于原表，丢弃之前的索引\n",
    "\n",
    "    \"\"\"计算Y_train=0、1的条件概率（拉普拉斯平滑）\"\"\"\n",
    "    Py0=(len(normal)+1)/(len(emails_train)+2)\n",
    "    Py1=(len(spam)+1)/(len(emails_train)+2)\n",
    "\n",
    "    \"\"\"计算X_train各特征向量取各特征值时的先验概率（拉普拉斯平滑）\"\"\"\n",
    "    \"\"\"计算垃圾邮件中,各特征向量的先验概率\"\"\"\n",
    "    vd=len(spam.content[0]) #特征向量的维度\n",
    "    spam_count_dict={} #用于保存content特征向量按列累加的结果\n",
    "    spam_count_prob={} #用于保存垃圾邮件中各特征向量出现的概率\n",
    "\n",
    "    #求content各特征向量按列累加的结果，用于计算各向量在训练集中出现的概率\n",
    "    for i in range(len(spam)):\n",
    "        for j in range(vd):\n",
    "            spam_count_dict[j]=spam_count_dict.get(j,0)+spam.content[i][j] #计算垃圾邮件中各特征向量出现的次数，即，求content各特征向量count按列累加的结果\n",
    "\n",
    "    for j in range(vd):\n",
    "        spam_count_prob[j]=(spam_count_dict.get(j,0)+1)/(len(spam)+2)#计算垃圾邮件中各特征向量出现的概率（拉普拉斯平滑）\n",
    "\n",
    "    \"\"\"计算正常邮件中,各特征向量的先验概率\"\"\"\n",
    "    normal_count_dict={} #用于保存content特征向量按列累加的结果\n",
    "    normal_count_prob={} #用于保存正常邮件中各特征向量出现的概率\n",
    "\n",
    "    #求content各特征向量按列累加的结果，用于计算各向量在训练集中出现的概率\n",
    "    for i in range(len(normal)):\n",
    "        for j in range(vd):\n",
    "            normal_count_dict[j]=normal_count_dict.get(j,0)+normal.content[i][j] #计算垃圾邮件中各特征向量出现的次数，即，求content各特征向量count按列累加的结果\n",
    "\n",
    "    for j in range(vd):\n",
    "        normal_count_prob[j]=(normal_count_dict.get(j,0)+1)/(len(normal)+2)#计算垃圾邮件中各特征向量出现的概率（拉普拉斯平滑）\n",
    "\n",
    "    \"\"\"计算各测试样本的后验概率\"\"\"\n",
    "    test_classify={} #用于保存测试集各样本的后验概率 P(Y|X)=P(Y)*P(X|Y)/P(X)\n",
    "    Px_spam={} #用于保存测试集各样本在垃圾邮件下的先验概率 P(X|Y)\n",
    "    Px_normal={} #用于保存测试集各样本在正常邮件下的先验概率 P(X|Y)\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            if X_test[i][j]!=0:\n",
    "                Px_spam[i]=Px_spam.get(i,1)*spam_count_prob.get(j)#计算垃圾邮件下，各测试样本的后验概率\n",
    "                Px_normal[i]=Px_normal.get(i,1)*normal_count_prob.get(j)#计算正常邮件下，各测试样本的后验概率\n",
    "\n",
    "        test_classify[i]=Py0*Px_normal.get(i,0),Py1*Px_spam.get(i,0) #后验概率P(Y|X)=P(Y)*P(X|Y)/P(X)\n",
    "\n",
    "    #比较各样本属于不同分类时(正常/垃圾)的后验概率，去后验概率大的为样本分类结果\n",
    "    results={} #用于存放邮件判定结果\n",
    "    for key,value in test_classify.items():\n",
    "        if value[0]<=value[1]: #value[0]-样本为正常邮件的后验概率，value[1]-样本为垃圾邮件的后验概率\n",
    "            results[key]=1\n",
    "        else:\n",
    "            results[key]=0\n",
    "\n",
    "    \"\"\"计算分类准确率\"\"\"\n",
    "    count=0 #计数，统计被正确分类的邮件数量\n",
    "    for key,value in results.items():\n",
    "        if value==Y_test[key]:\n",
    "            count+=1\n",
    "    score=count/len(Y_test)\n",
    "    \n",
    "    print (\"测试样本预测分类为(按索引排序)：\")\n",
    "    print (results.values(),\"\\n\")\n",
    "    print (\"测试样本实际分类为(按索引排序)：\")\n",
    "    print (Y_test,\"\\n\")\n",
    "    print (\"NB模型分类准确率为：{0}%\".format(score*100))\n",
    "\n",
    "    return results,score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试NB模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>招商银行信用卡电子账单2018年6月?-?07/13?￥1,540.00?＄?0.00?￥1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>密码重置邮件-来自智联招聘?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>信用管家消费提醒?-?尊敬的邓莎女士：?您好，感谢您选择招商银行信用卡！?￥2189?￥58...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple 提供的收据?-?收据?APPLE?ID?348708632@qq.com付款信息...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>信用管家消费提醒?-?尊敬的邓莎女士：?您好，感谢您选择招商银行信用卡！?￥1540?￥64...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6月20日徐晨阳《硅谷创新机制解密》报告?-?各位校友：?通知请见：https://www....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中国科学技术大学六十周年校庆纪念活动 校友邀请函?-??尊敬的校友：?您好！红专并进一甲子，...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>少女心晒一“夏”，ELLE Club等你解锁夏季最潮玩法！（?-?如果您不能正常浏览此邮件，...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>网上购票系统--用户支付通知?-??尊敬的?邓女士：?您好！?您于2018年06月04日在中...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  type\n",
       "0  招商银行信用卡电子账单2018年6月?-?07/13?￥1,540.00?＄?0.00?￥1...     0\n",
       "1                                     密码重置邮件-来自智联招聘?     0\n",
       "2  信用管家消费提醒?-?尊敬的邓莎女士：?您好，感谢您选择招商银行信用卡！?￥2189?￥58...     0\n",
       "3  Apple 提供的收据?-?收据?APPLE?ID?348708632@qq.com付款信息...     0\n",
       "4  信用管家消费提醒?-?尊敬的邓莎女士：?您好，感谢您选择招商银行信用卡！?￥1540?￥64...     0\n",
       "5  6月20日徐晨阳《硅谷创新机制解密》报告?-?各位校友：?通知请见：https://www....     0\n",
       "6  中国科学技术大学六十周年校庆纪念活动 校友邀请函?-??尊敬的校友：?您好！红专并进一甲子，...     0\n",
       "7  少女心晒一“夏”，ELLE Club等你解锁夏季最潮玩法！（?-?如果您不能正常浏览此邮件，...     1\n",
       "8  网上购票系统--用户支付通知?-??尊敬的?邓女士：?您好！?您于2018年06月04日在中...     0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据\n",
    "emails=pd.read_csv(r\"E:\\python\\data\\emails_spam.csv\",encoding=\"utf-8\")\n",
    "emails.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清洗数据\n",
    "def text_format():\n",
    "    import jieba\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    \n",
    "    print (\"待处理文本格式要求:utf-8编码格式，仅包含待处理文本，每行为一条文本\")\n",
    "    text_path=input(\"请输入待清洗文本路径+名字：\")\n",
    "    \n",
    "    #加载用户自定义词典用于分词\n",
    "    userdict_path=input(\"请输入自定义分词词典路径+名字(可不输入)：\")\n",
    "    if userdict_path !=\"\":\n",
    "        jieba.load_userdict(userdict_path)\n",
    "        \n",
    "    #根据用户输入地址，读取文件\n",
    "    with open(text_path,\"r\",encoding=\"utf-8\") as file:\n",
    "        text=file.readlines()\n",
    "    for i in range(len(text)):\n",
    "        text[i]=text[i].strip()\n",
    "    \n",
    "    #定义一个空列表，用于存放分词后的文本，长度和text一致\n",
    "    text_word=[[] for i in range(len(text))]\n",
    "    \n",
    "    splitter=re.compile(r\"\\W+|\\d+|[a-z]+\") #正则匹配，去除文本中的符号、数字、字母等非中文字符的元素\n",
    "    for i in range(len(text)):\n",
    "        text[i]=splitter.split(text[i].lower())\n",
    "        text[i]=[word for word in text[i] if len(word)>1] #每条文本已经被分为一段一段的句子，每条文本此时是一个list，先去除其中字段长度小于等于1的单词\n",
    "        for word in text[i]:\n",
    "            text_word[i].extend(jieba.lcut(word))\n",
    "        text_word[i]=\" \".join(text_word[i]) #为了便于TfidfVectorizer等文本向量化处理，将每条标题用元素用空格连起来\n",
    "    \n",
    "    return text_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "待处理文本格式要求:utf-8编码格式，仅包含待处理文本，每行为一条文本\n",
      "请输入待清洗文本路径+名字：E:\\python\\data\\emails_spam.txt\n",
      "请输入自定义分词词典路径+名字(可不输入)：\n"
     ]
    }
   ],
   "source": [
    "emails_format=text_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#建立训练集、测试集\n",
    "label=emails.type.tolist()\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(emails_format,label,test_size=0.2,random_state=7)\n",
    "\n",
    "#加载并处理停用词典\n",
    "with open(r\"E:\\python\\data\\stopwords.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "    stop_words=file.readlines()\n",
    "for i in range(len(stop_words)):\n",
    "    stop_words[i]=stop_words[i].strip(\"\\n\")\n",
    "    \n",
    "#构成词袋模型，记录各个词出现的次数\n",
    "cv=CountVectorizer(stop_words=stop_words)\n",
    "X_train_count=cv.fit_transform(X_train)\n",
    "X_test_count=cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将数据带入NB模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试样本预测分类为(按索引排序)：\n",
      "dict_values([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
      "\n",
      "测试样本实际分类为(按索引排序)：\n",
      "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0] \n",
      "\n",
      "NB模型分类准确率为：86.66666666666667%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({0: 0,\n",
       "  1: 0,\n",
       "  2: 0,\n",
       "  3: 1,\n",
       "  4: 0,\n",
       "  5: 1,\n",
       "  6: 0,\n",
       "  7: 0,\n",
       "  8: 0,\n",
       "  9: 0,\n",
       "  10: 0,\n",
       "  11: 0,\n",
       "  12: 0,\n",
       "  13: 0,\n",
       "  14: 0},\n",
       " 0.8666666666666667)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将数据带入NB模型进行测试\n",
    "wheel_nb(X_train_count.toarray(),Y_train,X_test_count.toarray(),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
