{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现思路(ID3)\n",
    "    1. 自定义信息熵计算函数，用于计算数据集的信息熵\n",
    "    2. 自定义数据划分函数，用于根据指定特征的指定取值，划分数据集\n",
    "    3. step2的自数据集作为输入给step1的函数，可以计算出按某指定特征的某指定取值(A=ai)划分的数据集的信息熵H(Di)，同时计算按某指定特征的某指定取值(A=ai)划分的数据集的样本概率|Di|/|D|\n",
    "    4. 遍历该特征各个取值，计算各取值下划分的数据集的信息熵H(Di)和样本概率|Di|/|D|，相乘，再求和得到得到特征A对数据集D的经验条件熵H(D|A)\n",
    "    5. 计算特征A对数据集的信息增益g(D,A)=H(D)-H(D|A)\n",
    "    6. 以此类推，计算各特征对数据集的信息增益，取信息增益最大的特征为最佳划分特征，得到树T1\n",
    "    7. 对T1各结点继续step3-6,选择信息增益最大的特征，继续划分数据，得到新的决策树\n",
    "    8. 直到信息增益小于阈值，或无特征可划分，或每个分支下的所有实例都具有相同的分类，决策树完成\n",
    "- **注意，ID3一直在分支，容易过拟合，因此需要对决策树剪枝，提高对测试集数据预测的性能**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from math import log\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "信息熵计算函数，用于计算数据集的信息熵\n",
    "输入：数据集，每一行是一条数据，最后一列是各条数据集的类别\n",
    "输出：该数据集的信息熵\n",
    "思路：\n",
    "建立一个字典，对数据集各数据的类别计数，\n",
    "从而计算各类别出现频率(作为概率pi)，\n",
    "最后调用信息熵公式计算 H(D)=-求和(pi*logpi)\n",
    "\"\"\"\n",
    "def calEntropy(dataset):\n",
    "    n=len(dataset)\n",
    "    labelCounts={}\n",
    "    \n",
    "    #对数据集各数据的类别计数\n",
    "    for data in dataset:\n",
    "        datalabel=data[-1] #取data最后一列，类别列\n",
    "        if datalabel not in labelCounts.keys():\n",
    "            labelCounts[datalabel]=0\n",
    "        labelCounts[datalabel]+=1\n",
    "    \n",
    "    entropy=0.0\n",
    "    \n",
    "    #计算各类别出现频率(作为概率pi),调用信息熵公式计算 H(D)=-求和(pi*logpi)\n",
    "    for key in labelCounts.keys():\n",
    "        prob=float(labelCounts[key])/n\n",
    "        entropy -= prob*log(prob,2)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "数据划分函数，用于根据指定特征的指定取值，划分数据集\n",
    "输入：数据集、特征所在列索引、特征取值\n",
    "输出：满足指定特征等于指定取值的数据子集\n",
    "\"\"\"\n",
    "def splitDataset(dataset,index,value):\n",
    "    subDataset=[]\n",
    "    for data in dataset:\n",
    "        if data[index]==value:\n",
    "            #抽取除了data[index]的内容(一个特征用于计算其对数据集的经验条件熵时，不需要此特征在子数据集中)\n",
    "            splitData=data[:index] #取索引之前的元素\n",
    "            splitData.extend(data[index+1:]) #再合并索引之后的元素\n",
    "            subDataset.append(splitData)\n",
    "    return subDataset\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "选择信息增益最大的特征作为数据集划分特征\n",
    "输入：数据集\n",
    "输出：该数据集的最佳划分特征\n",
    "\"\"\"\n",
    "def chooseFeature(dataset):\n",
    "    #初始化\n",
    "    numFeature=len(dataset[0])-1 #因为最后一列是类别\n",
    "    baseEntropy=calEntropy(dataset) #H(D)\n",
    "    bestInfoGain=0.0\n",
    "    bestFeatureIndex=-1\n",
    "    \n",
    "    #创建特征A各取值a的列表\n",
    "    for i in range(numFeature):\n",
    "        featureList=[data[i] for data in dataset]\n",
    "        uniqueValue=set(featureList)\n",
    "        empEntropy=0.0 #初始化特征A对数据集D的经验条件熵H(D|A)\n",
    "        \n",
    "        #计算特征A各取值a的信息熵H(Di)和样本概率|Di|/|D|，并相乘\n",
    "        for value in uniqueValue:\n",
    "            subDataset=splitDataset(dataset,i,value) #(列索引为i的特征)特征A取value值所划分的子数据集\n",
    "            prob=len(subDataset)/float(len(dataset)) #计算|Di|/|D|\n",
    "            empEntropy += prob*calEntropy(subDataset) #H(D|A)\n",
    "        \n",
    "        #取信息增益最大的特征为最佳划分特征\n",
    "        infoGain=baseEntropy-empEntropy #信息增益\n",
    "        if infoGain>bestInfoGain:\n",
    "            bestInfoGain=infoGain\n",
    "            bestFeatureIndex=i\n",
    "    return bestFeatureIndex\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "对数据集各数据类别进行计数排序\n",
    "\"\"\"\n",
    "def majorClass(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    \n",
    "    #对classCount按value降序排序\n",
    "    sortedClassCount=sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0] #返回类别最大的类别名\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "主函数：递归构建决策树\n",
    "输入：数据集(list类型)，数据集特征列表(按在数据集的位置排序)(list类型)\n",
    "输出：该数据集的决策树\n",
    "思路：【递归】\n",
    "    1. 若数据集属于同一类，则返回该类别，划分停止\n",
    "    2. 若数据集所有特征已经遍历，返回当前计数最多的类别为该结点类别，划分停止\n",
    "    3. 否则继续分支，调用chooseFeature()函数，选择当前数据集最优特征\n",
    "    4. 遍历当前最优特征各属性值，划分数据集，并递归调用自身createTree()构建子数据集的决策树\n",
    "    5. 完成\n",
    "\"\"\"\n",
    "def createTree(dataset,featureLabels):\n",
    "    classList=[data[-1] for data in dataset] #取数据集各数据类别\n",
    "    \n",
    "    #若数据集属于同一类，则返回该类别，划分停止\n",
    "    if classList.count(classList[0])==len(classList):\n",
    "        return classList[0]\n",
    "    \n",
    "    #若数据集所有特征已经遍历，返回当前计数最多的类别为该结点类别，划分停止\n",
    "    if len(dataset[0])==1:\n",
    "        return majorClass(classList)\n",
    "    \n",
    "    #否则继续分支，调用chooseFeature()函数，选择当前数据集最优特征\n",
    "    bestFeatureIndex=chooseFeature(dataset)\n",
    "    bestFeature=featureLabels[bestFeatureIndex]\n",
    "    \n",
    "    #用于存储决策树，字典结构存储树的所有信息，并可体现包含关系\n",
    "    desitionTree={bestFeature:{}} \n",
    "    del(featureLabels[bestFeatureIndex]) #删除已被用于划分数据的特征\n",
    "    \n",
    "    #得到当前最优划分特征的各属性值\n",
    "    featureValues=[data[bestFeatureIndex] for data in dataset]\n",
    "    uniqueValues=set(featureValues)\n",
    "    \n",
    "    #遍历当前最优特征各属性值，划分数据集，并递归调用自身createTree()构建子数据集的决策树\n",
    "    for value in uniqueValues:\n",
    "        #得到已删除当前最优划分特征的特征列表,用于递归调用\n",
    "        subFeatureLabels=featureLabels[:] \n",
    "       \n",
    "        #用当前最优划分特征的指定值分割子数据集，用于递归调用\n",
    "        subData=splitDataset(dataset,bestFeatureIndex,value) \n",
    "        desitionTree[bestFeature][value]=createTree(subData,subFeatureLabels)\n",
    "    return desitionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试\n",
    "- 西瓜分类数据集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermalon=pd.read_csv(r\"D:\\python\\data\\watermalon.txt\",sep=\"\\t\")\n",
    "watermalon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '是'],\n",
       " ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '是'],\n",
       " ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '是'],\n",
       " ['青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '是'],\n",
       " ['浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '是'],\n",
       " ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '是'],\n",
       " ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', '是'],\n",
       " ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '硬滑', '是'],\n",
       " ['乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', '否'],\n",
       " ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', '否'],\n",
       " ['浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', '否'],\n",
       " ['浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', '否'],\n",
       " ['青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', '否'],\n",
       " ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', '否'],\n",
       " ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '否'],\n",
       " ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', '否'],\n",
       " ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', '否']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermalon_list=np.array(watermalon).tolist() #构建数据集\n",
    "watermalon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'纹理': {'模糊': '否',\n",
       "  '清晰': {'根蒂': {'硬挺': '否',\n",
       "    '稍蜷': {'色泽': {'乌黑': {'触感': {'硬滑': '是', '软粘': '否'}}, '青绿': '是'}},\n",
       "    '蜷缩': '是'}},\n",
       "  '稍糊': {'触感': {'硬滑': '否', '软粘': '是'}}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=watermalon.columns.tolist()[0:-1] #提取特征列表\n",
    "my_tree=createTree(watermalon_list,features)\n",
    "my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
